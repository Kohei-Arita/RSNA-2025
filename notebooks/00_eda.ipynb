{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03435d90",
   "metadata": {},
   "source": [
    "# RSNA-2025 EDA / Baseline (Colab)\n",
    "\n",
    "このノートブックは Colab 実行を前提とし、GCS バケット `rsna2025-prod` から `train.csv` と `train_localizers.csv` を読み込み、EDA → ベースライン学習 → 参考用の推論関数雛形までをまとめます。\n",
    "\n",
    "- 実行順序: セットアップ → データロード → EDA 可視化 → ベースライン学習/検証\n",
    "- データ配置: GCS（`gs://rsna2025-prod/`）\n",
    "- 参考リポジトリ: `https://github.com/Kohei-Arita/RSNA-2025.git`（必要に応じてclone）\n",
    "\n",
    "注意: Kaggle の `/kaggle/input/...` 参照コードは Colab では使用しません。GCS から直接読み込みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ（Colab）: 依存導入・GCS認証・GitHub clone\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # pip を Python から実行（ノートブックマジックを使わない）\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib', 'gcsfs', 'fsspec', 'pydicom'], check=True)\n",
    "\n",
    "    # GCP 認証（ADC）。対話UIが出ます\n",
    "    from google.colab import auth  # type: ignore\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # 作業ディレクトリを /content に設定\n",
    "    os.chdir('/content')\n",
    "\n",
    "    # GitHub から本リポジトリを取得\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "\n",
    "    # Colab ランタイムにリポジトリの src を追加（任意）\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "# GCS バケット設定\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) データ読込（GCS / gcsfs 経由）\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "pd.options.display.max_columns = 120\n",
    "\n",
    "SEED = 130\n",
    "\n",
    "train_uri = f'{GCS_BASE}/train.csv'\n",
    "trainloc_uri = f'{GCS_BASE}/train_localizers.csv'\n",
    "\n",
    "# ColabのADCを gcsfs が利用（storage_options={'token': 'cloud'}）\n",
    "train = pd.read_csv(train_uri, storage_options={'token': 'cloud'})\n",
    "train_localizers = pd.read_csv(trainloc_uri, storage_options={'token': 'cloud'})\n",
    "\n",
    "print(f\"Number of training series: {train.shape[0]}\")\n",
    "print(f\"Number of localization rows: {train_localizers.shape[0]}\")\n",
    "\n",
    "display(train.head())\n",
    "display(train_localizers.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) EDA 可視化\n",
    "# 年齢を数値化（\"xx - yy\" 形式の先頭、または数字抽出）\n",
    "df_age_str = train['PatientAge'].astype(str)\n",
    "age_first = df_age_str.str.split(' - ').str[0]\n",
    "age_vals = pd.to_numeric(age_first.str.extract(r'([0-9]+(?:\\.[0-9]+)?)')[0], errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(age_vals.dropna(), bins=20, edgecolor='k')\n",
    "plt.title('Patient Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=train, x='PatientSex', palette='pastel')\n",
    "plt.title('Patient Sex Distribution')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 箱ひげ（欠損を除去）\n",
    "tmp = train.copy()\n",
    "tmp['age_num'] = age_vals\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Aneurysm Present', y='age_num', data=tmp)\n",
    "plt.xticks([0,1], ['Absent','Present'])\n",
    "plt.title('Age vs. Aneurysm Presence')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=train, x='Modality', palette='Set2')\n",
    "plt.title('Imaging Modality Counts')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "label_cols = [\n",
    "    'Left Infraclinoid Internal Carotid Artery','Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery','Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery','Right Middle Cerebral Artery','Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery','Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery','Right Posterior Communicating Artery',\n",
    "    'Basilar Tip','Other Posterior Circulation'\n",
    "]\n",
    "\n",
    "# CSV の実カラムと突き合わせ（存在する列のみ使う）\n",
    "existing_labels = [c for c in label_cols if c in train.columns]\n",
    "if len(existing_labels) < len(label_cols):\n",
    "    print('Warning: 一部のラベル列が見つかりませんでした。検出:', len(existing_labels))\n",
    "\n",
    "prevalences = train[existing_labels].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=prevalences.values, y=prevalences.index, palette='coolwarm')\n",
    "plt.title('Aneurysm Prevalence by Vascular Location')\n",
    "plt.xlabel('Prevalence')\n",
    "plt.show()\n",
    "\n",
    "# 相関ヒートマップ\n",
    "cols_for_corr = existing_labels + (['Aneurysm Present'] if 'Aneurysm Present' in train.columns else [])\n",
    "if len(cols_for_corr) >= 2:\n",
    "    plt.figure(figsize=(12,10))\n",
    "    cor_mat = train[cols_for_corr].corr(numeric_only=True)\n",
    "    sns.heatmap(cor_mat, annot=False, cmap='vlag')\n",
    "    plt.title('Correlation Matrix of Label Columns')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a16226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) ベースライン前処理・学習・評価（GBM）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 特徴量: 年齢・性別（Male=1）・モダリティone-hot\n",
    "x_age = age_vals.fillna(age_vals.median())\n",
    "X = pd.DataFrame({\n",
    "    'age': x_age,\n",
    "    'sex': (train['PatientSex'] == 'Male').astype(int)\n",
    "})\n",
    "mod_dummies = pd.get_dummies(train['Modality'], prefix='mod')\n",
    "X = pd.concat([X, mod_dummies], axis=1)\n",
    "\n",
    "# 目的変数\n",
    "if train['Aneurysm Present'].dtype != np.int64 and train['Aneurysm Present'].dtype != np.int32:\n",
    "    y = train['Aneurysm Present'].astype(int)\n",
    "else:\n",
    "    y = train['Aneurysm Present']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "gbm = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=8,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "val_probs = gbm.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_probs)\n",
    "print(f\"GBM Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# 後続で利用するために列名を保持\n",
    "MOD_COLUMNS = list(mod_dummies.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c18b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 参考: 簡易予測関数とサブミッション雛形（ローカル検証用）\n",
    "# Kaggle のサービングAPIは Colab では起動しません。ここでは簡易に presence を全ラベルに複写した雛形を作ります。\n",
    "ID_COL = 'SeriesInstanceUID'\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery','Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery','Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery','Right Middle Cerebral Artery','Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery','Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery','Right Posterior Communicating Artery',\n",
    "    'Basilar Tip','Other Posterior Circulation','Aneurysm Present'\n",
    "]\n",
    "\n",
    "# フォールバック平均\n",
    "available_label_cols = [c for c in LABEL_COLS if c in train.columns]\n",
    "means = train[available_label_cols].mean(numeric_only=True).to_dict()\n",
    "train_idx = train.set_index(ID_COL)\n",
    "\n",
    "def _build_feature_row(row):\n",
    "    age_val = pd.to_numeric(str(row['PatientAge']).split(' - ')[0], errors='coerce')\n",
    "    if pd.isna(age_val):\n",
    "        age_val = age_vals.median()\n",
    "    sex_val = 1 if row['PatientSex'] == 'Male' else 0\n",
    "    feats = {'age': age_val, 'sex': sex_val}\n",
    "    for m in MOD_COLUMNS:\n",
    "        feats[m] = 1 if m == f\"mod_{row['Modality']}\" else 0\n",
    "    return pd.DataFrame([feats])\n",
    "\n",
    "# デモ: 学習データの先頭N件に対して presence を推定し、全ラベルに複写\n",
    "def build_submission_preview(n=10):\n",
    "    rows = []\n",
    "    for sid, row in train.head(n).set_index(ID_COL).iterrows():\n",
    "        feat_df = _build_feature_row(row)\n",
    "        prob = float(gbm.predict_proba(feat_df)[:, 1][0])\n",
    "        out = [sid] + [prob for _ in LABEL_COLS]\n",
    "        rows.append(out)\n",
    "    df = pl.DataFrame(rows, schema=[ID_COL] + LABEL_COLS)\n",
    "    return df\n",
    "\n",
    "submission_preview = build_submission_preview(10)\n",
    "submission_preview.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ（Colab）: 依存導入・GCS認証・GitHub clone\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # pip を Python から実行（ノートブックマジックを使わない）\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib',\n",
    "                    'gcsfs', 'fsspec', 'pydicom', 'nibabel',\n",
    "                    'opencv-python-headless',\n",
    "                    'pylibjpeg[all]'], check=True)  # DICOMの可逆/非可逆圧縮に備える\n",
    "\n",
    "    # GCP 認証（ADC）。対話UIが出ます\n",
    "    from google.colab import auth  # type: ignore\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # 作業ディレクトリ\n",
    "    os.chdir('/content')\n",
    "\n",
    "    # GitHub から本リポジトリを取得（必要に応じて）\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "\n",
    "    # Colab ランタイムにリポジトリの src を追加（任意）\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "# GCS バケット設定\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5) 画像EDA（GCS版：他者コードの内容をGCSに適合）\n",
    "# 参照情報は Kaggle ノートの記述を維持し、入出力のみ GCS に切替\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, random, io, tempfile, math\n",
    "\n",
    "import fsspec\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import nibabel as nib\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- GCS FS 準備 ---\n",
    "fs = fsspec.filesystem(\"gcs\", token=\"cloud\")  # ColabのADCを使用\n",
    "\n",
    "# --- (Kaggle相当) test.csv のヘッド確認：存在すれば読む ---\n",
    "# Kaggleコードでは ../input/.../kaggle_evaluation/test.csv を参照していたため、\n",
    "# あなたのバケットの kaggle_evaluation/test.csv を優先的に探します（無ければスキップ）\n",
    "test_uri = f\"{GCS_BASE}/kaggle_evaluation/test.csv\"\n",
    "try:\n",
    "    if fs.exists(test_uri):\n",
    "        with fs.open(test_uri, 'rb') as f:\n",
    "            test = pd.read_csv(f)\n",
    "        print(\"test: No more data to show (head)\")\n",
    "        display(test.head())\n",
    "    else:\n",
    "        print(f\"[Info] {test_uri} が見つからないため test.csv のプレビューはスキップします。\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warn] test.csv の読み込みをスキップしました: {e}\")\n",
    "\n",
    "# --- train_localizers: 既に上流で train_localizers を読み込んでいる前提 ---\n",
    "# Kaggleノートの説明文相当は省略、データ構造は上流のDataFrameで満たしています\n",
    "print(\"train_localizers head (from GCS):\")\n",
    "display(train_localizers.head(2))\n",
    "\n",
    "# --- Modality の分布（他者コードの value_counts 相当）\n",
    "print(\"train['Modality'].value_counts()\")\n",
    "print(train['Modality'].value_counts())\n",
    "\n",
    "# --- 数値列の相関（他者コードの heatmap 相当）\n",
    "numerical_cols = [\n",
    "    'PatientAge',\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "corr_mat = train[numerical_cols].corr(numeric_only=True)\n",
    "sns.heatmap(corr_mat, annot=True, cmap='summer')\n",
    "plt.title(\"Correlation Between Numerical Features\")\n",
    "plt.show()\n",
    "\n",
    "# --- DICOM シリーズ（series/**.dcm）の列挙とサンプル表示 ---\n",
    "# Kaggleコード: glob('../input/.../series/**/*.dcm') → GCS: fs.find('gs://.../series')\n",
    "print(\"Listing DICOMs under GCS ... (this may take some time for the first call)\")\n",
    "all_series_paths = fs.find(f\"{GCS_BASE}/series\")\n",
    "train_images = [p for p in all_series_paths if p.lower().endswith('.dcm')]\n",
    "print(\"Total number of images: \", len(train_images))\n",
    "\n",
    "# 代表1枚のメタ情報＆ピクセル配列タイプの確認（他者コードの print(ds), type/im.dtype/im.shape 相当）\n",
    "def read_dicom_from_gcs(path: str) -> pydicom.dataset.FileDataset:\n",
    "    # fsspec file-like をそのまま pydicom に渡せます\n",
    "    with fs.open(path, 'rb') as f:\n",
    "        ds = pydicom.dcmread(f, force=True)  # 圧縮対応は pylibjpeg[all] のインストールで担保\n",
    "        try:\n",
    "            # ビューワ向けに VOI LUT を適用したピクセルを得る（あれば）\n",
    "            arr = ds.pixel_array\n",
    "            try:\n",
    "                arr = apply_voi_lut(arr, ds)\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            arr = None\n",
    "    return ds\n",
    "\n",
    "if len(train_images) > 0:\n",
    "    sample_path = train_images[min(1, len(train_images)-1)]\n",
    "    ds = read_dicom_from_gcs(sample_path)\n",
    "    print(ds)  # ファイルタイプなどの概要\n",
    "    try:\n",
    "        im = ds.pixel_array\n",
    "        print(type(im))\n",
    "        print(im.dtype)\n",
    "        print(im.shape)\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] pixel_array 取得に失敗: {e}\")\n",
    "\n",
    "    # 1枚表示（他者コード: pylab.imshow(im, cmap=...）相当）\n",
    "    try:\n",
    "        import matplotlib.pylab as pylab\n",
    "        pylab.imshow(ds.pixel_array, cmap=pylab.cm.gist_gray)\n",
    "        pylab.axis('on')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] DICOM表示に失敗: {e}\")\n",
    "\n",
    "# グリッドで複数表示（他者コードの for ループ可視化に相当）\n",
    "def show_random_dcms(paths, rows=4, cols=5):\n",
    "    n = min(len(paths), rows*cols)\n",
    "    if n == 0:\n",
    "        print(\"[Info] 表示対象のDICOMがありません。\")\n",
    "        return\n",
    "    sel = random.sample(paths, n) if len(paths) > n else paths[:n]\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    for i, p in enumerate(sel, 1):\n",
    "        try:\n",
    "            ds = read_dicom_from_gcs(p)\n",
    "            ax = fig.add_subplot(rows, cols, i)\n",
    "            ax.imshow(ds.pixel_array, cmap=plt.cm.bone)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "        except Exception as e:\n",
    "            # 壊れたファイルがあっても全体は止めない\n",
    "            pass\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_dcms(train_images, rows=4, cols=5)\n",
    "\n",
    "# --- NIfTI セグメンテーション（segmentations/*/*.nii）の列挙＆表示 ---\n",
    "# Kaggleコードのパターン: '../input/.../segmentations/*/*'\n",
    "print(\"Listing NIfTI masks under GCS ...\")\n",
    "all_seg_paths = fs.find(f\"{GCS_BASE}/segmentations\")  # 再帰列挙\n",
    "mrscans = sorted([p for p in all_seg_paths if p.lower().endswith('.nii')])\n",
    "print(\"num of segmentation mask\", len(mrscans))\n",
    "\n",
    "def load_nifti_from_gcs(path: str):\n",
    "    # nib は file-like 直接は非対応のことがあるため、一時ファイルに流す\n",
    "    with fs.open(path, 'rb') as fsrc, tempfile.NamedTemporaryFile(suffix=\".nii\", delete=False) as fdst:\n",
    "        fdst.write(fsrc.read())\n",
    "        tmp_path = fdst.name\n",
    "    img = nib.load(tmp_path).get_fdata()\n",
    "    return img, tmp_path  # tmp_pathは後で削除してもOK\n",
    "\n",
    "# 1例：shape 確認と1スライス表示（Kaggleの例：imshow(img[:,:,10])）\n",
    "if len(mrscans) > 0:\n",
    "    try:\n",
    "        img, tmp = load_nifti_from_gcs(mrscans[0])\n",
    "        print(\"NIfTI shape:\", img.shape)\n",
    "        plt.imshow(img[:, :, min(10, img.shape[2]-1)])\n",
    "        plt.title(\"Example NIfTI slice\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        try:\n",
    "            os.remove(tmp)\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] NIfTI 読み込み表示に失敗: {e}\")\n",
    "\n",
    "# 複数スライスをグリッドで可視化（他者コードの multi_dim_plot を踏襲）\n",
    "def multi_dim_plot(multi_dim_array, id, num_slices=25):  # ※元コードのバリエーションに合わせて 25\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    plt.title(f'Plotting first {num_slices} slices of {id}', fontdict={'fontsize': 20})\n",
    "    plt.yticks([]); plt.xticks([])\n",
    "    xy = int(math.sqrt(num_slices))\n",
    "    for i in range(num_slices):\n",
    "        ax = fig.add_subplot(xy, xy, i + 1)\n",
    "        ax.imshow(multi_dim_array[..., :num_slices][..., i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ランダムに2例を可視化（元ノートの振る舞いを踏襲）\n",
    "if len(mrscans) > 0:\n",
    "    k = min(2, len(mrscans))\n",
    "    for msk_path in random.sample(mrscans, k):\n",
    "        try:\n",
    "            m, tmp = load_nifti_from_gcs(msk_path)\n",
    "            multi_dim_plot(m, id=msk_path.split('/')[-1], num_slices=25)\n",
    "            try:\n",
    "                os.remove(tmp)\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(f\"[Warn] NIfTI 可視化に失敗: {e}\")\n",
    "else:\n",
    "    print(\"[Info] 表示対象の NIfTI マスクがありません。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
