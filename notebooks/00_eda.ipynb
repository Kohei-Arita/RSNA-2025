{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03435d90",
   "metadata": {},
   "source": [
    "# RSNA-2025 EDA / Baseline (Colab)\n",
    "\n",
    "このノートブックは Colab 実行を前提とし、GCS バケット `rsna2025-prod` から `train.csv` と `train_localizers.csv` を読み込み、EDA → ベースライン学習 → 参考用の推論関数雛形までをまとめます。\n",
    "\n",
    "- 実行順序: セットアップ → データロード → EDA 可視化 → ベースライン学習/検証\n",
    "- データ配置: GCS（`gs://rsna2025-prod/`）\n",
    "- 参考リポジトリ: `https://github.com/Kohei-Arita/RSNA-2025.git`（必要に応じてclone）\n",
    "\n",
    "注意: Kaggle の `/kaggle/input/...` 参照コードは Colab では使用しません。GCS から直接読み込みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ（Colab）: 依存導入・GCS認証・GitHub clone\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # pip を Python から実行（ノートブックマジックを使わない）\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib', 'gcsfs', 'fsspec', 'pydicom'], check=True)\n",
    "\n",
    "    # GCP 認証（ADC）。対話UIが出ます\n",
    "    from google.colab import auth  # type: ignore\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # 作業ディレクトリを /content に設定\n",
    "    os.chdir('/content')\n",
    "\n",
    "    # GitHub から本リポジトリを取得\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "\n",
    "    # Colab ランタイムにリポジトリの src を追加（任意）\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "# GCS バケット設定\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) データ読込（GCS / gcsfs 経由）\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "pd.options.display.max_columns = 120\n",
    "\n",
    "SEED = 130\n",
    "\n",
    "train_uri = f'{GCS_BASE}/train.csv'\n",
    "trainloc_uri = f'{GCS_BASE}/train_localizers.csv'\n",
    "\n",
    "# ColabのADCを gcsfs が利用（storage_options={'token': 'cloud'}）\n",
    "train = pd.read_csv(train_uri, storage_options={'token': 'cloud'})\n",
    "train_localizers = pd.read_csv(trainloc_uri, storage_options={'token': 'cloud'})\n",
    "\n",
    "print(f\"Number of training series: {train.shape[0]}\")\n",
    "print(f\"Number of localization rows: {train_localizers.shape[0]}\")\n",
    "\n",
    "display(train.head())\n",
    "display(train_localizers.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) EDA 可視化\n",
    "# 年齢を数値化（\"xx - yy\" 形式の先頭、または数字抽出）\n",
    "df_age_str = train['PatientAge'].astype(str)\n",
    "age_first = df_age_str.str.split(' - ').str[0]\n",
    "age_vals = pd.to_numeric(age_first.str.extract(r'([0-9]+(?:\\.[0-9]+)?)')[0], errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(age_vals.dropna(), bins=20, edgecolor='k')\n",
    "plt.title('Patient Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=train, x='PatientSex', palette='pastel')\n",
    "plt.title('Patient Sex Distribution')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 箱ひげ（欠損を除去）\n",
    "tmp = train.copy()\n",
    "tmp['age_num'] = age_vals\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Aneurysm Present', y='age_num', data=tmp)\n",
    "plt.xticks([0,1], ['Absent','Present'])\n",
    "plt.title('Age vs. Aneurysm Presence')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=train, x='Modality', palette='Set2')\n",
    "plt.title('Imaging Modality Counts')\n",
    "plt.xlabel('Modality')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "label_cols = [\n",
    "    'Left Infraclinoid Internal Carotid Artery','Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery','Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery','Right Middle Cerebral Artery','Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery','Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery','Right Posterior Communicating Artery',\n",
    "    'Basilar Tip','Other Posterior Circulation'\n",
    "]\n",
    "\n",
    "# CSV の実カラムと突き合わせ（存在する列のみ使う）\n",
    "existing_labels = [c for c in label_cols if c in train.columns]\n",
    "if len(existing_labels) < len(label_cols):\n",
    "    print('Warning: 一部のラベル列が見つかりませんでした。検出:', len(existing_labels))\n",
    "\n",
    "prevalences = train[existing_labels].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=prevalences.values, y=prevalences.index, palette='coolwarm')\n",
    "plt.title('Aneurysm Prevalence by Vascular Location')\n",
    "plt.xlabel('Prevalence')\n",
    "plt.show()\n",
    "\n",
    "# 相関ヒートマップ\n",
    "cols_for_corr = existing_labels + (['Aneurysm Present'] if 'Aneurysm Present' in train.columns else [])\n",
    "if len(cols_for_corr) >= 2:\n",
    "    plt.figure(figsize=(12,10))\n",
    "    cor_mat = train[cols_for_corr].corr(numeric_only=True)\n",
    "    sns.heatmap(cor_mat, annot=False, cmap='vlag')\n",
    "    plt.title('Correlation Matrix of Label Columns')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a16226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) データ統計の詳細分析\n",
    "# 年齢とAneurysm Presentの関係を詳しく見る\n",
    "print(\"=== データ統計の詳細 ===\")\n",
    "print(f\"Total series: {train.shape[0]}\")\n",
    "print(f\"Unique patients: {train['PatientID'].nunique()}\")\n",
    "print(f\"Unique studies: {train['StudyInstanceUID'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Aneurysm Presentの分布\n",
    "print(\"Aneurysm Present distribution:\")\n",
    "print(train['Aneurysm Present'].value_counts())\n",
    "print(f\"Positive rate: {train['Aneurysm Present'].mean():.2%}\")\n",
    "print()\n",
    "\n",
    "# 各ラベルの陽性率\n",
    "print(\"Label-wise positive rates:\")\n",
    "for col in existing_labels:\n",
    "    print(f\"  {col}: {train[col].mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# 年齢グループ別のAneurysm Present率\n",
    "train['age_group'] = pd.cut(age_vals, bins=[0, 40, 50, 60, 70, 100], \n",
    "                            labels=['<40', '40-49', '50-59', '60-69', '70+'])\n",
    "age_aneurysm = train.groupby('age_group')['Aneurysm Present'].agg(['mean', 'count'])\n",
    "print(\"Age group vs Aneurysm Present:\")\n",
    "display(age_aneurysm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c18b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 局在化データ (train_localizers) の探索\n",
    "print(\"=== Localizer データの分析 ===\")\n",
    "\n",
    "# train_localizersのマージ\n",
    "merged = train.merge(train_localizers, on='SeriesInstanceUID', how='left')\n",
    "localizer_coverage = (~merged['label'].isna()).mean()\n",
    "print(f\"Localizer coverage: {localizer_coverage:.1%}\")\n",
    "\n",
    "# 部位ラベルごとの局在化データ数\n",
    "localizer_counts = train_localizers.groupby('label').size().sort_values(ascending=False)\n",
    "print(\"\\nLocalizer counts by label:\")\n",
    "display(localizer_counts)\n",
    "\n",
    "# 局在化データがあるシリーズとないシリーズの特徴\n",
    "has_localizer = train['SeriesInstanceUID'].isin(train_localizers['SeriesInstanceUID'])\n",
    "print(f\"\\nSeries with localizers: {has_localizer.sum()} / {len(train)} ({has_localizer.mean():.1%})\")\n",
    "\n",
    "# 局在化データの有無とAneurysm Presentの関係\n",
    "localizer_vs_aneurysm = pd.crosstab(has_localizer, train['Aneurysm Present'], \n",
    "                                    normalize='columns', margins=True)\n",
    "print(\"\\nLocalizer availability vs Aneurysm Present (column %):\")\n",
    "display(localizer_vs_aneurysm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 画像EDA用の追加セットアップ\n",
    "# 画像処理用ライブラリのインストール（既にインストール済みでなければ）\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        import pydicom\n",
    "        import nibabel\n",
    "        print(\"画像処理ライブラリは既にインストール済みです\")\n",
    "    except ImportError:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                        'pydicom', 'nibabel', 'opencv-python-headless', 'pylibjpeg[all]'], check=True)\n",
    "        print(\"画像処理ライブラリをインストールしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 画像EDA（DICOM/NIfTI の探索）\n",
    "# GCSから画像データを読み込んで可視化\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, random, io, tempfile, math\n",
    "\n",
    "import fsspec\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import nibabel as nib\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- GCS FS 準備 ---\n",
    "fs = fsspec.filesystem(\"gcs\", token=\"cloud\")  # ColabのADCを使用\n",
    "\n",
    "# --- (Kaggle相当) test.csv のヘッド確認：存在すれば読む ---\n",
    "# Kaggleコードでは ../input/.../kaggle_evaluation/test.csv を参照していたため、\n",
    "# あなたのバケットの kaggle_evaluation/test.csv を優先的に探します（無ければスキップ）\n",
    "test_uri = f\"{GCS_BASE}/kaggle_evaluation/test.csv\"\n",
    "try:\n",
    "    if fs.exists(test_uri):\n",
    "        with fs.open(test_uri, 'rb') as f:\n",
    "            test = pd.read_csv(f)\n",
    "        print(\"test: No more data to show (head)\")\n",
    "        display(test.head())\n",
    "    else:\n",
    "        print(f\"[Info] {test_uri} が見つからないため test.csv のプレビューはスキップします。\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warn] test.csv の読み込みをスキップしました: {e}\")\n",
    "\n",
    "# --- train_localizers: 既に上流で train_localizers を読み込んでいる前提 ---\n",
    "# Kaggleノートの説明文相当は省略、データ構造は上流のDataFrameで満たしています\n",
    "print(\"train_localizers head (from GCS):\")\n",
    "display(train_localizers.head(2))\n",
    "\n",
    "# --- Modality の分布（他者コードの value_counts 相当）\n",
    "print(\"train['Modality'].value_counts()\")\n",
    "print(train['Modality'].value_counts())\n",
    "\n",
    "# --- 数値列の相関（他者コードの heatmap 相当）\n",
    "numerical_cols = [\n",
    "    'PatientAge',\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "corr_mat = train[numerical_cols].corr(numeric_only=True)\n",
    "sns.heatmap(corr_mat, annot=True, cmap='summer')\n",
    "plt.title(\"Correlation Between Numerical Features\")\n",
    "plt.show()\n",
    "\n",
    "# --- DICOM シリーズ（series/**.dcm）の列挙とサンプル表示 ---\n",
    "# Kaggleコード: glob('../input/.../series/**/*.dcm') → GCS: fs.find('gs://.../series')\n",
    "print(\"Listing DICOMs under GCS ... (this may take some time for the first call)\")\n",
    "all_series_paths = fs.find(f\"{GCS_BASE}/series\")\n",
    "train_images = [p for p in all_series_paths if p.lower().endswith('.dcm')]\n",
    "print(\"Total number of images: \", len(train_images))\n",
    "\n",
    "# 代表1枚のメタ情報＆ピクセル配列タイプの確認（他者コードの print(ds), type/im.dtype/im.shape 相当）\n",
    "def read_dicom_from_gcs(path: str) -> pydicom.dataset.FileDataset:\n",
    "    # fsspec file-like をそのまま pydicom に渡せます\n",
    "    with fs.open(path, 'rb') as f:\n",
    "        ds = pydicom.dcmread(f, force=True)  # 圧縮対応は pylibjpeg[all] のインストールで担保\n",
    "        try:\n",
    "            # ビューワ向けに VOI LUT を適用したピクセルを得る（あれば）\n",
    "            arr = ds.pixel_array\n",
    "            try:\n",
    "                arr = apply_voi_lut(arr, ds)\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            arr = None\n",
    "    return ds\n",
    "\n",
    "if len(train_images) > 0:\n",
    "    sample_path = train_images[min(1, len(train_images)-1)]\n",
    "    ds = read_dicom_from_gcs(sample_path)\n",
    "    print(ds)  # ファイルタイプなどの概要\n",
    "    try:\n",
    "        im = ds.pixel_array\n",
    "        print(type(im))\n",
    "        print(im.dtype)\n",
    "        print(im.shape)\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] pixel_array 取得に失敗: {e}\")\n",
    "\n",
    "    # 1枚表示（他者コード: pylab.imshow(im, cmap=...）相当）\n",
    "    try:\n",
    "        import matplotlib.pylab as pylab\n",
    "        pylab.imshow(ds.pixel_array, cmap=pylab.cm.gist_gray)\n",
    "        pylab.axis('on')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] DICOM表示に失敗: {e}\")\n",
    "\n",
    "# グリッドで複数表示（他者コードの for ループ可視化に相当）\n",
    "def show_random_dcms(paths, rows=4, cols=5):\n",
    "    n = min(len(paths), rows*cols)\n",
    "    if n == 0:\n",
    "        print(\"[Info] 表示対象のDICOMがありません。\")\n",
    "        return\n",
    "    sel = random.sample(paths, n) if len(paths) > n else paths[:n]\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    for i, p in enumerate(sel, 1):\n",
    "        try:\n",
    "            ds = read_dicom_from_gcs(p)\n",
    "            ax = fig.add_subplot(rows, cols, i)\n",
    "            ax.imshow(ds.pixel_array, cmap=plt.cm.bone)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "        except Exception as e:\n",
    "            # 壊れたファイルがあっても全体は止めない\n",
    "            pass\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_dcms(train_images, rows=4, cols=5)\n",
    "\n",
    "# --- NIfTI セグメンテーション（segmentations/*/*.nii）の列挙＆表示 ---\n",
    "# Kaggleコードのパターン: '../input/.../segmentations/*/*'\n",
    "print(\"Listing NIfTI masks under GCS ...\")\n",
    "all_seg_paths = fs.find(f\"{GCS_BASE}/segmentations\")  # 再帰列挙\n",
    "mrscans = sorted([p for p in all_seg_paths if p.lower().endswith('.nii')])\n",
    "print(\"num of segmentation mask\", len(mrscans))\n",
    "\n",
    "def load_nifti_from_gcs(path: str):\n",
    "    # nib は file-like 直接は非対応のことがあるため、一時ファイルに流す\n",
    "    with fs.open(path, 'rb') as fsrc, tempfile.NamedTemporaryFile(suffix=\".nii\", delete=False) as fdst:\n",
    "        fdst.write(fsrc.read())\n",
    "        tmp_path = fdst.name\n",
    "    img = nib.load(tmp_path).get_fdata()\n",
    "    return img, tmp_path  # tmp_pathは後で削除してもOK\n",
    "\n",
    "# 1例：shape 確認と1スライス表示（Kaggleの例：imshow(img[:,:,10])）\n",
    "if len(mrscans) > 0:\n",
    "    try:\n",
    "        img, tmp = load_nifti_from_gcs(mrscans[0])\n",
    "        print(\"NIfTI shape:\", img.shape)\n",
    "        plt.imshow(img[:, :, min(10, img.shape[2]-1)])\n",
    "        plt.title(\"Example NIfTI slice\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        try:\n",
    "            os.remove(tmp)\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] NIfTI 読み込み表示に失敗: {e}\")\n",
    "\n",
    "# 複数スライスをグリッドで可視化（他者コードの multi_dim_plot を踏襲）\n",
    "def multi_dim_plot(multi_dim_array, id, num_slices=25):  # ※元コードのバリエーションに合わせて 25\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    plt.title(f'Plotting first {num_slices} slices of {id}', fontdict={'fontsize': 20})\n",
    "    plt.yticks([]); plt.xticks([])\n",
    "    xy = int(math.sqrt(num_slices))\n",
    "    for i in range(num_slices):\n",
    "        ax = fig.add_subplot(xy, xy, i + 1)\n",
    "        ax.imshow(multi_dim_array[..., :num_slices][..., i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ランダムに2例を可視化（元ノートの振る舞いを踏襲）\n",
    "if len(mrscans) > 0:\n",
    "    k = min(2, len(mrscans))\n",
    "    for msk_path in random.sample(mrscans, k):\n",
    "        try:\n",
    "            m, tmp = load_nifti_from_gcs(msk_path)\n",
    "            multi_dim_plot(m, id=msk_path.split('/')[-1], num_slices=25)\n",
    "            try:\n",
    "                os.remove(tmp)\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(f\"[Warn] NIfTI 可視化に失敗: {e}\")\n",
    "else:\n",
    "    print(\"[Info] 表示対象の NIfTI マスクがありません。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
