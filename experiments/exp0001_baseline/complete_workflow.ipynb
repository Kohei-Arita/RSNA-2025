{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9b2958",
   "metadata": {},
   "source": [
    "# RSNA-2025 統合ワークフロー (exp0001_baseline)\n",
    "\n",
    "このノートブックは training → evaluation → inference を1本で実行します。\n",
    "\n",
    "- セッション内で完結（モデルはメモリ/ローカルに保存）\n",
    "- 実行順: 上から順に\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152329e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 由来ノートブック: training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9582e5",
   "metadata": {},
   "source": [
    "# RSNA-2025 ベースライン学習 (exp0001_baseline)\n",
    "\n",
    "このノートブックでは、ベースラインモデル（GradientBoosting）の学習を実行します。\n",
    "\n",
    "- 実験ID: exp0001_baseline\n",
    "- モデル: GradientBoostingClassifier\n",
    "- 特徴量: 年齢、性別、モダリティ\n",
    "- 目的変数: Aneurysm Present\n",
    "\n",
    "## 実験設定\n",
    "\n",
    "実験の再現性を確保するため、以下の設定を使用します：\n",
    "- SEED = 130\n",
    "- test_size = 0.2\n",
    "- stratified split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59789268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ（Colab）\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    # pip を Python から実行\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib', 'gcsfs', 'fsspec'], check=True)\n",
    "\n",
    "    # GCP 認証（ADC）\n",
    "    from google.colab import auth  # type: ignore\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # 作業ディレクトリを設定\n",
    "    os.chdir('/content')\n",
    "    \n",
    "    # GitHub から本リポジトリを取得\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "\n",
    "    # リポジトリの src を追加\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "# GCS バケット設定\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) データ読込\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "SEED = 130\n",
    "\n",
    "train_uri = f'{GCS_BASE}/train.csv'\n",
    "\n",
    "# ColabのADCを gcsfs が利用\n",
    "train = pd.read_csv(train_uri, storage_options={'token': 'cloud'})\n",
    "\n",
    "print(f\"Number of training series: {train.shape[0]}\")\n",
    "display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 特徴量エンジニアリング\n",
    "# 年齢を数値化（\"xx - yy\" 形式の先頭、または数字抽出）\n",
    "df_age_str = train['PatientAge'].astype(str)\n",
    "age_first = df_age_str.str.split(' - ').str[0]\n",
    "age_vals = pd.to_numeric(age_first.str.extract(r'([0-9]+(?:\\.[0-9]+)?)')[0], errors='coerce')\n",
    "\n",
    "# 特徴量作成: 年齢・性別（Male=1）・モダリティone-hot\n",
    "x_age = age_vals.fillna(age_vals.median())\n",
    "X = pd.DataFrame({\n",
    "    'age': x_age,\n",
    "    'sex': (train['PatientSex'] == 'Male').astype(int)\n",
    "})\n",
    "mod_dummies = pd.get_dummies(train['Modality'], prefix='mod')\n",
    "X = pd.concat([X, mod_dummies], axis=1)\n",
    "\n",
    "# 目的変数\n",
    "if train['Aneurysm Present'].dtype != np.int64 and train['Aneurysm Present'].dtype != np.int32:\n",
    "    y = train['Aneurysm Present'].astype(int)\n",
    "else:\n",
    "    y = train['Aneurysm Present']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 学習・検証データ分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Validation target distribution:\\n{y_val.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5088bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) モデル学習\n",
    "gbm = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=8,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# 訓練データでの予測\n",
    "train_probs = gbm.predict_proba(X_train)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, train_probs)\n",
    "print(f\"GBM Training AUC: {train_auc:.4f}\")\n",
    "\n",
    "# 検証データでの予測\n",
    "val_probs = gbm.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_probs)\n",
    "print(f\"GBM Validation AUC: {val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 特徴量重要度の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': gbm.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "display(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) モデルと設定の保存\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# モデルの保存\n",
    "models_dir = Path('models/exp0001_baseline')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(models_dir / 'gbm_baseline.pkl', 'wb') as f:\n",
    "    pickle.dump(gbm, f)\n",
    "\n",
    "# 列名の保存（推論で必要）\n",
    "MOD_COLUMNS = list(mod_dummies.columns)\n",
    "metadata = {\n",
    "    'feature_columns': list(X.columns),\n",
    "    'mod_columns': MOD_COLUMNS,\n",
    "    'train_auc': float(train_auc),\n",
    "    'val_auc': float(val_auc),\n",
    "    'seed': SEED,\n",
    "    'model_params': gbm.get_params()\n",
    "}\n",
    "\n",
    "with open(models_dir / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {models_dir}\")\n",
    "print(f\"Training AUC: {train_auc:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234050f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 由来ノートブック: evaluation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09aef7e",
   "metadata": {},
   "source": [
    "# RSNA-2025 ベースライン評価 (exp0001_baseline)\n",
    "\n",
    "このノートブックでは、学習済みモデルの評価とOut-of-Fold予測を実行します。\n",
    "\n",
    "- 実験ID: exp0001_baseline\n",
    "- モデル: 学習済みGradientBoostingClassifier\n",
    "- 評価指標: AUC、閾値最適化、混同行列\n",
    "\n",
    "## 主な内容\n",
    "1. 学習済みモデルのロード\n",
    "2. Out-of-Fold（OOF）予測\n",
    "3. 閾値最適化\n",
    "4. 評価指標の可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e582c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib', 'gcsfs', 'fsspec'], check=True)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    os.chdir('/content')\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) モデルとメタデータのロード\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "models_dir = Path('models/exp0001_baseline')\n",
    "\n",
    "# モデルのロード\n",
    "with open(models_dir / 'gbm_baseline.pkl', 'rb') as f:\n",
    "    gbm = pickle.load(f)\n",
    "\n",
    "# メタデータのロード\n",
    "with open(models_dir / 'metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"Model loaded successfully\")\n",
    "print(f\"Training AUC: {metadata['train_auc']:.4f}\")\n",
    "print(f\"Validation AUC: {metadata['val_auc']:.4f}\")\n",
    "print(f\"Feature columns: {metadata['feature_columns'][:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) データの再読み込みと特徴量作成\n",
    "train_uri = f'{GCS_BASE}/train.csv'\n",
    "train = pd.read_csv(train_uri, storage_options={'token': 'cloud'})\n",
    "\n",
    "# 特徴量の再作成（training.ipynbと同じ処理）\n",
    "df_age_str = train['PatientAge'].astype(str)\n",
    "age_first = df_age_str.str.split(' - ').str[0]\n",
    "age_vals = pd.to_numeric(age_first.str.extract(r'([0-9]+(?:\\.[0-9]+)?)')[0], errors='coerce')\n",
    "\n",
    "x_age = age_vals.fillna(age_vals.median())\n",
    "X = pd.DataFrame({\n",
    "    'age': x_age,\n",
    "    'sex': (train['PatientSex'] == 'Male').astype(int)\n",
    "})\n",
    "mod_dummies = pd.get_dummies(train['Modality'], prefix='mod')\n",
    "X = pd.concat([X, mod_dummies], axis=1)\n",
    "\n",
    "# 目的変数\n",
    "if train['Aneurysm Present'].dtype != np.int64 and train['Aneurysm Present'].dtype != np.int32:\n",
    "    y = train['Aneurysm Present'].astype(int)\n",
    "else:\n",
    "    y = train['Aneurysm Present']\n",
    "\n",
    "print(f\"Data loaded: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77661663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Out-of-Fold (OOF) 予測\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SEED = metadata['seed']\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros(len(X))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train_fold = X.iloc[train_idx]\n",
    "    y_train_fold = y.iloc[train_idx]\n",
    "    X_val_fold = X.iloc[val_idx]\n",
    "    \n",
    "    # フォールドごとにモデルを学習\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    fold_model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=8,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    fold_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # OOF予測\n",
    "    oof_preds[val_idx] = fold_model.predict_proba(X_val_fold)[:, 1]\n",
    "    \n",
    "    # フォールドごとのAUC\n",
    "    fold_auc = roc_auc_score(y.iloc[val_idx], oof_preds[val_idx])\n",
    "    print(f\"Fold {fold+1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# 全体のOOF AUC\n",
    "overall_oof_auc = roc_auc_score(y, oof_preds)\n",
    "print(f\"\\nOverall OOF AUC: {overall_oof_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7831d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) ROC曲線と閾値最適化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, oof_preds)\n",
    "\n",
    "# Youden's J統計量で最適閾値を探索\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {overall_oof_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, \n",
    "           label=f'Optimal threshold = {optimal_threshold:.3f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Aneurysm Present')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Sensitivity at optimal: {tpr[optimal_idx]:.3f}\")\n",
    "print(f\"Specificity at optimal: {1-fpr[optimal_idx]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ade08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 混同行列と分類レポート\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_binary = (oof_preds >= optimal_threshold).astype(int)\n",
    "\n",
    "# 混同行列の表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 正規化なし\n",
    "cm = confusion_matrix(y, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Aneurysm', 'Aneurysm'])\n",
    "disp.plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('Confusion Matrix (Count)')\n",
    "\n",
    "# 正規化あり\n",
    "cm_norm = confusion_matrix(y, y_pred_binary, normalize='true')\n",
    "disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=['No Aneurysm', 'Aneurysm'])\n",
    "disp_norm.plot(ax=axes[1], cmap='Blues')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 分類レポート\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred_binary, target_names=['No Aneurysm', 'Aneurysm']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) OOF予測の保存\n",
    "outputs_dir = Path('outputs/oof/exp0001_baseline')\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# OOF予測をDataFrameとして保存\n",
    "oof_df = pd.DataFrame({\n",
    "    'SeriesInstanceUID': train['SeriesInstanceUID'],\n",
    "    'Aneurysm Present': y,\n",
    "    'oof_pred': oof_preds\n",
    "})\n",
    "\n",
    "oof_df.to_csv(outputs_dir / 'oof_predictions.csv', index=False)\n",
    "\n",
    "# 評価メトリクスの保存\n",
    "metrics = {\n",
    "    'overall_oof_auc': float(overall_oof_auc),\n",
    "    'optimal_threshold': float(optimal_threshold),\n",
    "    'sensitivity': float(tpr[optimal_idx]),\n",
    "    'specificity': float(1-fpr[optimal_idx])\n",
    "}\n",
    "\n",
    "with open(outputs_dir / 'metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"OOF predictions saved to: {outputs_dir}\")\n",
    "print(f\"Overall OOF AUC: {overall_oof_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c834c22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 由来ノートブック: inference.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c2a57",
   "metadata": {},
   "source": [
    "# RSNA-2025 ベースライン推論 (exp0001_baseline)\n",
    "\n",
    "このノートブックでは、学習済みモデルを使用した推論と提出ファイル生成（参考用）を行います。\n",
    "\n",
    "- 実験ID: exp0001_baseline\n",
    "- モデル: 学習済みGradientBoostingClassifier\n",
    "- 出力: 14ラベルの予測確率\n",
    "\n",
    "## 主な内容\n",
    "1. 学習済みモデルのロード\n",
    "2. 特徴量作成関数の定義\n",
    "3. 予測関数の実装\n",
    "4. サンプル予測の実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) セットアップ\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "\n",
    "if IN_COLAB:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', 'pip'], check=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                    'pandas', 'polars', 'seaborn', 'scikit-learn', 'matplotlib', 'gcsfs', 'fsspec'], check=True)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    os.chdir('/content')\n",
    "    REPO_URL = 'https://github.com/Kohei-Arita/RSNA-2025.git'\n",
    "    REPO_DIR = Path('/content/RSNA-2025')\n",
    "    if not REPO_DIR.exists():\n",
    "        subprocess.run(['git', 'clone', REPO_URL], check=True)\n",
    "    os.chdir('/content/RSNA-2025')\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "GCS_BUCKET = 'rsna2025-prod'\n",
    "GCS_BASE = f'gs://{GCS_BUCKET}'\n",
    "print('GCS_BASE =', GCS_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) モデルとメタデータのロード\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "models_dir = Path('models/exp0001_baseline')\n",
    "\n",
    "# モデルのロード\n",
    "with open(models_dir / 'gbm_baseline.pkl', 'rb') as f:\n",
    "    gbm = pickle.load(f)\n",
    "\n",
    "# メタデータのロード（特徴量の列名など）\n",
    "with open(models_dir / 'metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "MOD_COLUMNS = metadata['mod_columns']\n",
    "print(\"Model loaded successfully\")\n",
    "print(f\"Feature columns: {metadata['feature_columns'][:5]}...\")\n",
    "print(f\"Modality columns: {MOD_COLUMNS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) ラベル定義（提出用）\n",
    "ID_COL = 'SeriesInstanceUID'\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present'\n",
    "]\n",
    "\n",
    "print(f\"Number of labels: {len(LABEL_COLS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eefbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 訓練データの読み込み（年齢の中央値計算用）\n",
    "train_uri = f'{GCS_BASE}/train.csv'\n",
    "train = pd.read_csv(train_uri, storage_options={'token': 'cloud'})\n",
    "\n",
    "# 年齢の中央値を計算（欠損値埋め用）\n",
    "df_age_str = train['PatientAge'].astype(str)\n",
    "age_first = df_age_str.str.split(' - ').str[0]\n",
    "age_vals = pd.to_numeric(age_first.str.extract(r'([0-9]+(?:\\.[0-9]+)?)')[0], errors='coerce')\n",
    "AGE_MEDIAN = age_vals.median()\n",
    "print(f\"Age median for imputation: {AGE_MEDIAN:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 特徴量作成関数\n",
    "def build_feature_row(row):\n",
    "    \"\"\"単一行から特徴量を作成\"\"\"\n",
    "    # 年齢の処理\n",
    "    age_str = str(row.get('PatientAge', ''))\n",
    "    age_val = pd.to_numeric(age_str.split(' - ')[0], errors='coerce')\n",
    "    if pd.isna(age_val):\n",
    "        age_val = AGE_MEDIAN\n",
    "    \n",
    "    # 性別の処理\n",
    "    sex_val = 1 if row.get('PatientSex', '') == 'Male' else 0\n",
    "    \n",
    "    # 特徴量辞書を作成\n",
    "    feats = {'age': age_val, 'sex': sex_val}\n",
    "    \n",
    "    # モダリティのone-hot encoding\n",
    "    modality = row.get('Modality', '')\n",
    "    for m in MOD_COLUMNS:\n",
    "        feats[m] = 1 if m == f\"mod_{modality}\" else 0\n",
    "    \n",
    "    return pd.DataFrame([feats])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebaf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 予測関数\n",
    "def predict_series(series_data):\n",
    "    \"\"\"シリーズデータから14ラベルの予測を生成\"\"\"\n",
    "    # 特徴量を作成\n",
    "    feat_df = build_feature_row(series_data)\n",
    "    \n",
    "    # presence (Aneurysm Present) の予測\n",
    "    presence_prob = float(gbm.predict_proba(feat_df)[:, 1][0])\n",
    "    \n",
    "    # 簡略化：全ラベルに同じ確率を使用\n",
    "    # 実際の提出では、ラベルごとに専用モデルを使用すべき\n",
    "    predictions = {label: presence_prob for label in LABEL_COLS}\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41588881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) サンプル予測（学習データの先頭N件で動作確認）\n",
    "def build_submission_preview(n=10):\n",
    "    \"\"\"学習データの先頭N件で予測を生成（動作確認用）\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for _, row in train.head(n).iterrows():\n",
    "        series_id = row[ID_COL]\n",
    "        predictions = predict_series(row.to_dict())\n",
    "        \n",
    "        # 行を作成（SeriesInstanceUID + 14ラベルの予測）\n",
    "        row_data = [series_id] + [predictions[label] for label in LABEL_COLS]\n",
    "        rows.append(row_data)\n",
    "    \n",
    "    # Polars DataFrameとして返す\n",
    "    df = pl.DataFrame(rows, schema=[ID_COL] + LABEL_COLS)\n",
    "    return df\n",
    "\n",
    "# 動作確認\n",
    "submission_preview = build_submission_preview(10)\n",
    "print(\"Submission preview:\")\n",
    "display(submission_preview.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 予測結果の保存（サンプル）\n",
    "outputs_dir = Path('outputs/preds/exp0001_baseline')\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSVとして保存（参考用）\n",
    "submission_preview.write_csv(outputs_dir / 'sample_predictions.csv')\n",
    "\n",
    "print(f\"Sample predictions saved to: {outputs_dir}\")\n",
    "print(f\"Shape: {submission_preview.shape}\")\n",
    "print(\"\\nNote: 本番のKaggle提出では、サービングAPIを使用します。\")\n",
    "print(\"このCSVは動作確認・ローカルテスト用です。\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
